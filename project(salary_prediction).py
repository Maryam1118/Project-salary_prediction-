# -*- coding: utf-8 -*-
"""Project(salary_prediction).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bjsmITmZzLlD82QzUuajhIGvZrTBdpNU
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# =====================================================
# PAGE CONFIG + STYLE
# =====================================================
st.set_page_config(page_title="Salary Prediction System", layout="wide")

st.markdown("""
<style>
.big-title {
    font-size:40px;
    font-weight:800;
    color:#1f77b4;
}
</style>
""", unsafe_allow_html=True)

st.markdown('<p class="big-title">ðŸ’¼ Salary Prediction Dashboard</p>', unsafe_allow_html=True)

# =====================================================
# LOAD DATA
# =====================================================
df = pd.read_csv("salary_dataset_2000.csv")
TARGET = "Salary"

# FIX: Drop rows where the target column (Salary) is NaN
df = df.dropna(subset=[TARGET])

# =====================================================
# SIDEBAR
# =====================================================
st.sidebar.title("ðŸ“˜ About Project")
st.sidebar.write(f"""
Algorithm: Random Forest Regressor
Dataset size: {len(df)} rows
Goal: Predict salary based on features
""")

# =====================================================
# SPLIT FEATURES
# =====================================================
X = df.drop(TARGET, axis=1)
y = df[TARGET]

num_features = X.select_dtypes(include=["int64","float64"]).columns
cat_features = X.select_dtypes(include=["object"]).columns

# =====================================================
# PREPROCESSING
# =====================================================
num_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="mean")),
    ("scaler", StandardScaler())
])

cat_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer([
    ("num", num_pipe, num_features),
    ("cat", cat_pipe, cat_features)
])

# =====================================================
# TRAIN MODEL
# =====================================================
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

rf = RandomForestRegressor(
    n_estimators=400,
    max_depth=15,
    random_state=42,
    n_jobs=-1
)

pipe = Pipeline([
    ("prep", preprocessor),
    ("model", rf)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

# =====================================================
# METRICS
# =====================================================
# =====================================================
# METRICS CALCULATION
# =====================================================
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Adjusted R2
n = X_test.shape[0]
p = X_test.shape[1]
adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)


# =====================================================
# TABS
# =====================================================
tab1, tab2, tab3 = st.tabs([
    "ðŸŽ¯ Prediction",
    "ðŸ“Š Model Performance",
    "ðŸ“ˆ Data Insights"
])

# =====================================================
# TAB 1 â€” PREDICTION
# =====================================================
with tab1:
    st.header("Enter Candidate Details")
    with st.form("predict_form"):
        input_data = {}
        for col in num_features:
            input_data[col] = st.number_input(col, float(df[col].min()), float(df[col].max()), float(df[col].mean()))
        for col in cat_features:
            input_data[col] = st.selectbox(col, sorted(df[col].unique()))
        submitted = st.form_submit_button("Predict Salary")

    if submitted:
        input_df = pd.DataFrame([input_data])
        pred = pipe.predict(input_df)[0]
        st.success(f"Predicted Salary: â‚¹ {round(pred,2)}")
        trees = pipe.named_steps["model"].estimators_
        transformed = pipe.named_steps["prep"].transform(input_df)
        preds = [tree.predict(transformed)[0] for tree in trees]
        st.write("Prediction Range:")
        st.write("Min:", round(min(preds),2))
        st.write("Max:", round(max(preds),2))
        result = input_df.copy()
        result["Predicted Salary"] = pred
        st.download_button("Download Prediction", result.to_csv(index=False), "prediction.csv")

# =====================================================
# TAB 2 â€” MODEL PERFORMANCE
# =====================================================
with tab2:
  st.header("ðŸ“Š Model Performance Metrics")

st.write("""
These evaluation metrics measure how accurately the model predicts salary.
Lower error values indicate better predictions, while higher RÂ² indicates stronger explanatory power.
""")

col1, col2, col3, col4, col5 = st.columns(5)

col1.metric("MAE", round(mae, 2))
col2.metric("MSE", round(mse, 2))
col3.metric("RMSE", round(rmse, 2))
col4.metric("RÂ² Score", round(r2, 4))
col5.metric("Adjusted RÂ²", round(adj_r2, 4))

st.info("""
ðŸ“Œ Interpretation Guide:
â€¢ MAE â†’ Average prediction error
â€¢ MSE â†’ Penalizes large errors
â€¢ RMSE â†’ Standard deviation of errors
â€¢ RÂ² â†’ % variance explained
â€¢ Adjusted RÂ² â†’ RÂ² corrected for number of features
""")

    st.subheader("ðŸ§  Feature Importance Analysis")
    st.write("This chart shows which features have the strongest influence on salary prediction.")
    names = pipe.named_steps["prep"].get_feature_names_out()
    imp = pipe.named_steps["model"].feature_importances_
    fi = pd.DataFrame({"Feature": names, "Importance": imp}).sort_values("Importance", ascending=False).head(10)
    fig = plt.figure()
    plt.barh(fi["Feature"], fi["Importance"])
    plt.gca().invert_yaxis()
    plt.xlabel("Importance Score")
    plt.ylabel("Features")
    st.pyplot(fig)

# =====================================================
# TAB 3 â€” DATA INSIGHTS
# =====================================================
with tab3:
    st.header("ðŸ’° Salary Distribution in Dataset")
    fig = plt.figure()
    plt.hist(df["Salary"], bins=30)
    plt.xlabel("Salary Range")
    plt.ylabel("Number of Employees")
    st.pyplot(fig)

    st.header("ðŸ“ˆ Relationship Between Features and Salary")
    for col in num_features:
        if col != "Salary":
            st.subheader(f"{col} vs Salary Relationship")
            fig = plt.figure()
            plt.scatter(df[col], df["Salary"])
            plt.xlabel(col)
            plt.ylabel("Salary")
            st.pyplot(fig)